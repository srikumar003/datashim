---
apiVersion: v1
kind: Pod
metadata:
  name: text-generation-inference
  labels:
    run: text-generation-inference
    dataset.0.id: "model-weights"
    dataset.0.useas: "mount"
spec:
  containers:
    - name: text-generation-inference
      image: ghcr.io/huggingface/text-generation-inference:1.3.4
      env:
        - name: RUST_BACKTRACE
          value: "full"
      command:
        - "text-generation-launcher"
        - "--model-id"
        - "google/flan-t5-base"
        - "--sharded"
        - "false"
        - "--port"
        - "8080"
        - "--huggingface-hub-cache"
        - "/tmp"
        - "--weights-cache-override"
        - "/mnt/datasets/model-weights/flan-t5-base"
      ports:
        - containerPort: 8080
          name: http
  nodeSelector:
    nvidia.com/gpu.product: ${GPU_TYPE}
  restartPolicy: Never
---
apiVersion: v1
kind: Service
metadata:
  name: text-generation-inference
spec:
  ports:
  - port: 8080
    protocol: TCP
    targetPort: 8080
  selector:
    run: text-generation-inference
  type: ClusterIP
